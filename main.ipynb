{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from data_handlers import tokenise, batch, get_batch\n",
    "import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = False\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "path = './data/penn/'\n",
    "batch_size = 40\n",
    "\n",
    "emsize = 400\n",
    "nhid = 1150\n",
    "nlayers = 3\n",
    "dropout = 0.5\n",
    "tied = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "\n",
    "dictionary = data_handlers.Dictionary()\n",
    "\n",
    "# Tokenise data to replace characters with integer indexes\n",
    "train_data, dictionary = tokenise(path+'train.txt', dictionary)\n",
    "val_data, dictionary   = tokenise(path+'valid.txt', dictionary)\n",
    "test_data, dictionary  = tokenise(path+'test.txt', dictionary)\n",
    "\n",
    "# Batch data: reshapes vector as matrix where number of columns j \n",
    "# is the batch size.\n",
    "train_data = batch(train_data, batch_size)\n",
    "val_data = batch(val_data, batch_size)\n",
    "test_data  = batch(test_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD MODEL\n",
    "\n",
    "ntokens = len(dictionary)\n",
    "LSTM = rnn.LSTMModel(ntokens, emsize, nhid, nlayers, dropout, tied).to(device)\n",
    "\n",
    "# TODO: Check loss matches paper\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING CODE\n",
    "\n",
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history\"\"\"\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)\n",
    "    \n",
    "\n",
    "def evaluate(model, data, ntokens, batch_size, bptt):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data.size(0) - 1, bptt):\n",
    "            x, y = get_batch(data, i)\n",
    "            output, hidden = model(x, y)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += len(x) * criterion(output_flat, targets).item()\n",
    "            hidden = repackage_hidden(hidden)\n",
    "    return total_loss / (len(data) - 1)\n",
    "            \n",
    "    \n",
    "def train(model, data, ntokens:int, batch_size:int, lr:float, bptt:int, clip):\n",
    "    log_interval = 1\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    for batch, i in enumerate(range(0, data.size(0)-1, bptt)):\n",
    "        inputs, targets = get_batch(data, i, bptt)\n",
    "        #Â For each batch, detach hidden state from state created in previous\n",
    "        # batches. Else, the model would attempt backpropagation through the \n",
    "        # entire dataset\n",
    "        hidden = repackage_hidden(hidden)\n",
    "        # Zero the gradients from previous iteration, ready for new values\n",
    "        model.zero_grad()\n",
    "        # Forward pass\n",
    "        output, hidden = model(inputs, hidden)\n",
    "        # Calculate loss\n",
    "        loss = criterion(output.view(-1, ntokens), targets.view(-1))\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        # TODO: Check clipping config\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        for p in model.parameters():\n",
    "            p.data.add_(-lr, p.grad.data)\n",
    "            \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed  = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | ms/batch {:5.2f} | '\n",
    "                    'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                epoch, batch, len(data) // bptt, lr,\n",
    "                elapsed * 1000 / log_interval, cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |     1/  663 batches | lr 0.40 | ms/batch 12070.84 | loss 18.39 | ppl 97453976.17\n",
      "| epoch   1 |     2/  663 batches | lr 0.40 | ms/batch 5872.26 | loss  9.16 | ppl  9468.02\n",
      "| epoch   1 |     3/  663 batches | lr 0.40 | ms/batch 5860.41 | loss  9.14 | ppl  9329.36\n",
      "| epoch   1 |     4/  663 batches | lr 0.40 | ms/batch 6018.52 | loss  9.32 | ppl 11179.73\n",
      "| epoch   1 |     5/  663 batches | lr 0.40 | ms/batch 6011.74 | loss  9.38 | ppl 11870.83\n",
      "| epoch   1 |     6/  663 batches | lr 0.40 | ms/batch 5941.86 | loss  9.45 | ppl 12696.52\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-485-70716cb6ef13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbptt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbptt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m89\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-481-80d14296d3b8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data, ntokens, batch_size, lr, bptt, clip)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Backpropagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# TODO: Check clipping config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TRAINING LOOP\n",
    "\n",
    "epochs = 3\n",
    "lr = 0.4\n",
    "bptt = 35\n",
    "clip = 0.25\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(LSTM, train_data, ntokens, batch_size, lr, bptt, clip)\n",
    "    val_loss = evaluate(LSTM, val_data, ntokens, batch_size, bptt)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "            'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                       val_loss, np.exp(val_loss)))\n",
    "    print('-' * 89)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn import WeightDrop\n",
    "import torch\n",
    "from torch.nn import Parameter\n",
    "\n",
    "module = torch.nn.GRUCell(2, 2)\n",
    "# weights = ['weight_hh']\n",
    "# weight_drop_gru = WeightDrop(gru, weights, dropout=0.9)\n",
    "\n",
    "# input_ = torch.randn(3, 2)\n",
    "# hidden_state = torch.randn(3, 2)\n",
    "# weight_drop_gru(input_, hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.9465],\n",
       "        [-0.0000, -0.7086],\n",
       "        [-0.3301, -1.0996],\n",
       "        [ 0.0000,  0.0371],\n",
       "        [-0.0000,  0.7389],\n",
       "        [ 0.0000, -0.0000],\n",
       "        [-0.0000,  0.0000],\n",
       "        [-0.0000, -0.0000]])"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.dropout(lstm.state_dict()['weight_hh_l0'], p=0.5, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_w = 'weight_hh'\n",
    "w = getattr(lstm, name_w)\n",
    "#del lstm.parameters[name_w]\n",
    "lstm.register_parameter(name_w+'_raw', Parameter(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lstm.state_dict()[name_w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.4608, -0.5012],\n",
       "         [ 0.5199, -0.2146],\n",
       "         [-0.4698,  0.0663],\n",
       "         [ 0.0585, -0.3524],\n",
       "         [ 0.0013,  0.1005],\n",
       "         [-0.5843, -0.6274],\n",
       "         [-0.0040, -0.1587],\n",
       "         [ 0.5232,  0.0326]], requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.2775, -0.6964],\n",
       "         [ 0.2408,  0.3445],\n",
       "         [-0.5694,  0.1093],\n",
       "         [-0.6746, -0.6683],\n",
       "         [-0.3519,  0.5631],\n",
       "         [-0.1682, -0.2012],\n",
       "         [ 0.4750, -0.1853],\n",
       "         [-0.2210,  0.2469]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.2406, -0.3876, -0.1915,  0.1368, -0.3688, -0.3195, -0.3975,  0.1552],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([ 0.2639,  0.6060,  0.2806,  0.1037,  0.0335, -0.5144, -0.5294,  0.1068],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.2775, -0.6964],\n",
       "         [ 0.2408,  0.3445],\n",
       "         [-0.5694,  0.1093],\n",
       "         [-0.6746, -0.6683],\n",
       "         [-0.3519,  0.5631],\n",
       "         [-0.1682, -0.2012],\n",
       "         [ 0.4750, -0.1853],\n",
       "         [-0.2210,  0.2469]], requires_grad=True)]"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(lstm.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight_ih', tensor([[ 0.1540, -0.2117],\n",
       "                      [-0.4895,  0.1811],\n",
       "                      [-0.5259,  0.2650],\n",
       "                      [ 0.5868,  0.2686],\n",
       "                      [-0.6825,  0.3709],\n",
       "                      [-0.2350,  0.4248]])),\n",
       "             ('weight_hh', tensor([[ 0.2631, -0.6679],\n",
       "                      [ 0.4857, -0.0733],\n",
       "                      [ 0.7027, -0.6393],\n",
       "                      [ 0.0815, -0.6032],\n",
       "                      [ 0.6067, -0.2080],\n",
       "                      [-0.0372, -0.1714]])),\n",
       "             ('bias_ih',\n",
       "              tensor([-0.0945,  0.3338,  0.5635, -0.0618, -0.4097, -0.2291])),\n",
       "             ('bias_hh',\n",
       "              tensor([-0.3066,  0.3881, -0.6168,  0.5579, -0.6611,  0.1860]))])"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -1.3927],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [-0.0000,  0.2186],\n",
       "        [-0.0000, -1.3365],\n",
       "        [-0.7039,  1.1263],\n",
       "        [-0.3364, -0.4024],\n",
       "        [ 0.0000, -0.3705],\n",
       "        [-0.0000,  0.4938]], grad_fn=<DropoutBackward>)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_w = getattr(lstm, name_w + '_raw')\n",
    "w = nn.functional.dropout(raw_w, p=0.5, training=True)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "new_state = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state['yo'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('yo', 1)])"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
